{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KM0cyNW2a0VO",
        "outputId": "c426f0fb-e1a7-4b03-801a-1e66c17235e2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SimpleITK"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u13Y0imibtHZ",
        "outputId": "c87662ea-ec53-4c5e-b6c4-9249142a0070"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: SimpleITK in /usr/local/lib/python3.7/dist-packages (2.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "GJm5-mLQOoQ1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, metrics, losses\n",
        "from tensorflow.keras.models import Model \n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import SimpleITK as sitk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive/nnfl')"
      ],
      "metadata": {
        "id": "S5HTILLWbS_y"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 2"
      ],
      "metadata": {
        "id": "o43SaxYCl-2P"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "qlR8jflvOoQ3"
      },
      "outputs": [],
      "source": [
        "class CustomLayer(Model):\n",
        "    def __init__(self,input_shape, filters, n_layers, is_down = True):\n",
        "        super(CustomLayer, self).__init__(name='CustomLayer')\n",
        "        self.clayers = []\n",
        "        filter1, filter2 = filters \n",
        "        \n",
        "        self.input_layer = layers.InputLayer(input_shape=(*input_shape, filter1))\n",
        "\n",
        "        for _ in range(n_layers):\n",
        "            self.clayers.append(layers.Conv3D(filter1, 5, strides=1, padding='same'))\n",
        "\n",
        "        if is_down:\n",
        "            self.out = layers.Conv3D(filter2, 2, strides=2, padding='valid')\n",
        "        else:\n",
        "            self.out = layers.Conv3DTranspose(filter2, 2, strides=2, padding='valid')\n",
        "        \n",
        "        self.prelu = layers.PReLU() \n",
        "        \n",
        "    def call(self, input_tensor1, input_tensor2=None, training=False):\n",
        "\n",
        "        if input_tensor2 is not None:\n",
        "            input_tensor = layers.Concatenate(axis=4)([input_tensor1, input_tensor2])\n",
        "        else:\n",
        "            input_tensor = input_tensor1\n",
        "\n",
        "        input_tensor = self.input_layer(input_tensor)\n",
        "        x = input_tensor\n",
        "        \n",
        "        for layer in self.clayers:\n",
        "            x = layer(x)\n",
        "        x += input_tensor1\n",
        "        out = self.out(x)\n",
        "        \n",
        "        return x, self.prelu(out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "eii9uvxfOoQ5"
      },
      "outputs": [],
      "source": [
        "class VNet(Model):\n",
        "    def __init__(self, input_shape, batch_size):\n",
        "        super(VNet, self).__init__(name='VNet')\n",
        "        self.batch_size = batch_size\n",
        "        self.input_layer = layers.InputLayer(input_shape=(input_shape), batch_size=self.batch_size)\n",
        "        self.layer1 = CustomLayer((128,128,64), (1,16), 1)\n",
        "        self.layer2 = CustomLayer((64,64,32), (16,32), 2)\n",
        "        self.layer3 = CustomLayer((32,32,16), (32,64), 3)\n",
        "        self.layer4 = CustomLayer((16,16,8), (64,128), 3)\n",
        "        self.layer5 = CustomLayer((8,8,4), (128,256), 3, False)\n",
        "        self.layer6 = CustomLayer((16,16,8), (256,128), 3, False)\n",
        "        self.layer7 = CustomLayer((32,32,16), (128,64), 3, False)\n",
        "        self.layer8 = CustomLayer((64,64,32), (64,32), 2, False)\n",
        "        self.layer9 = layers.Conv3D(32, 5, strides=1, padding='same')\n",
        "        self.layer10 = layers.Conv3D(1, 1, padding='same')\n",
        "\n",
        "\n",
        "\n",
        "    def call(self, input_tensor, training = False):\n",
        "        input_tensor = self.input_layer(input_tensor)\n",
        "        o1, l1 = self.layer1(input_tensor)\n",
        "        o2, l2 = self.layer2(l1)\n",
        "        o3, l3 = self.layer3(l2)\n",
        "        o4, l4 = self.layer4(l3)\n",
        "        _, l5 = self.layer5(l4)\n",
        "        _, l6 = self.layer6(l5, o4)\n",
        "        _, l7 = self.layer7(l6, o3)\n",
        "        _, l8 = self.layer8(l7, o2)\n",
        "        l8_ = layers.Concatenate(axis=4)([l8, o1])\n",
        "        l9 = self.layer9(l8_)\n",
        "        l9 += l8\n",
        "        l10 = self.layer10(l9)\n",
        "        return tf.nn.softmax(l10)\n",
        "\n",
        "class VNet_without_skip(Model):\n",
        "    def __init__(self, input_shape, batch_size):\n",
        "        super(VNet_without_skip, self).__init__(name='VNet')\n",
        "        self.batch_size = batch_size\n",
        "        self.input_layer = layers.InputLayer(input_shape=(input_shape), batch_size=self.batch_size)\n",
        "        self.layer1 = CustomLayer((128,128,64), (1,16), 1)\n",
        "        self.layer2 = CustomLayer((64,64,32), (16,32), 2)\n",
        "        self.layer3 = CustomLayer((32,32,16), (32,64), 3)\n",
        "        self.layer4 = CustomLayer((16,16,8), (64,128), 3)\n",
        "        self.layer5 = CustomLayer((8,8,4), (128,256), 3, False)\n",
        "        self.layer6 = CustomLayer((16,16,8), (256,128), 3, False)\n",
        "        self.layer7 = CustomLayer((32,32,16), (128,64), 3, False)\n",
        "        self.layer8 = CustomLayer((64,64,32), (64,32), 2, False)\n",
        "        self.layer9 = layers.Conv3D(32, 5, strides=1, padding='same')\n",
        "        self.layer10 = layers.Conv3D(1, 1, padding='same')\n",
        "\n",
        "\n",
        "\n",
        "    def call(self, input_tensor, training = False):\n",
        "        input_tensor = self.input_layer(input_tensor)\n",
        "        o1, l1 = self.layer1(input_tensor)\n",
        "        o2, l2 = self.layer2(l1)\n",
        "        o3, l3 = self.layer3(l2)\n",
        "        o4, l4 = self.layer4(l3)\n",
        "        _, l5 = self.layer5(l4)\n",
        "        _, l6 = self.layer6(l5)\n",
        "        _, l7 = self.layer7(l6)\n",
        "        _, l8 = self.layer8(l7)\n",
        "        l9 = self.layer9(l8)\n",
        "        l9 += l8\n",
        "        l10 = self.layer10(l9)\n",
        "        return tf.nn.softmax(l10)\n",
        "\n",
        "class VNet_with_extra_layer(Model):\n",
        "    def __init__(self, input_shape, batch_size):\n",
        "        super(VNet_with_extra_layer, self).__init__(name='VNet')\n",
        "        self.batch_size = batch_size\n",
        "        self.input_layer = layers.InputLayer(input_shape=(input_shape), batch_size=self.batch_size)\n",
        "        self.layer1 = CustomLayer((128,128,64), (1,16), 1)\n",
        "        self.layer2 = CustomLayer((64,64,32), (16,32), 2)\n",
        "        self.layer3 = CustomLayer((32,32,16), (32,64), 3)\n",
        "        self.layer4 = CustomLayer((16,16,8), (64,128), 3)\n",
        "        self.extra1 = CustomLayer((8,8,4), (128,128), 3)\n",
        "        self.layer5 = CustomLayer((4,4,2), (128,256), 3, False)\n",
        "        self.extra2 = CustomLayer((8,8,4), (256,256), 3, False)\n",
        "        self.layer6 = CustomLayer((16,16,8), (256,128), 3, False)\n",
        "        self.layer7 = CustomLayer((32,32,16), (128,64), 3, False)\n",
        "        self.layer8 = CustomLayer((64,64,32), (64,32), 2, False)\n",
        "        self.layer9 = layers.Conv3D(32, 5, strides=1, padding='same')\n",
        "        self.layer10 = layers.Conv3D(1, 1, padding='same')\n",
        "\n",
        "\n",
        "\n",
        "    def call(self, input_tensor, training = False):\n",
        "        input_tensor = self.input_layer(input_tensor)\n",
        "        o1, l1 = self.layer1(input_tensor)\n",
        "        o2, l2 = self.layer2(l1)\n",
        "        o3, l3 = self.layer3(l2)\n",
        "        o4, l4 = self.layer4(l3)\n",
        "        eo1, el1 = self.extra1(l4)\n",
        "        _, l5 = self.layer5(el1)\n",
        "        _, el2 = self.extra2(l5, eo1)\n",
        "        _, l6 = self.layer6(el2, o4)\n",
        "        _, l7 = self.layer7(l6, o3)\n",
        "        _, l8 = self.layer8(l7, o2)\n",
        "        l8_ = layers.Concatenate(axis=4)([l8, o1])\n",
        "        l9 = self.layer9(l8_)\n",
        "        l9 += l8\n",
        "        l10 = self.layer10(l9)\n",
        "        return tf.nn.softmax(l10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRjnFghoOoQ7",
        "outputId": "28aa1553-2ef1-41e7-e981-51a77ad27387"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 16, 16, 8, 64) (None, 8, 8, 4, 128)\n",
            "(None, 8, 8, 4, 128) (None, 4, 4, 2, 128)\n",
            "(None, 4, 4, 2, 128) (None, 8, 8, 4, 256)\n",
            "(None, 8, 8, 4, 256) (None, 16, 16, 8, 256)\n",
            "(None, 16, 16, 8, 64) (None, 8, 8, 4, 128)\n",
            "(None, 8, 8, 4, 128) (None, 4, 4, 2, 128)\n",
            "(None, 4, 4, 2, 128) (None, 8, 8, 4, 256)\n",
            "(None, 8, 8, 4, 256) (None, 16, 16, 8, 256)\n",
            "1/1 [==============================] - 4s 4s/step\n"
          ]
        }
      ],
      "source": [
        "# x = np.random.rand(1,128,128,64,1)\n",
        "# x = tf.constant(x)\n",
        "# mod = VNet_with_extra_layer(input_shape=(128,128,64,1,), batch_size=1)\n",
        "# mod.compile()\n",
        "\n",
        "# p = mod.predict(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Pipeline:"
      ],
      "metadata": {
        "id": "uuzuIktaifks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset:\n",
        "\n",
        "    def __init__(self, dir:str, out_shape = (128,128,64), image_channels = 1, mask_channels = 1, batch_size= 10):\n",
        "      self.dir = dir\n",
        "      self.image_channels = image_channels\n",
        "      self.batch_size = batch_size\n",
        "      self.mask_channels = mask_channels\n",
        "      self.params = dict()\n",
        "      self.params['dstRes'] = np.asarray([1,1,1.5],dtype=float)\n",
        "      self.params['VolSize'] = np.asarray([*out_shape],dtype=int)\n",
        "      self.params['normDir'] = False\n",
        "  \n",
        "\n",
        "    def getNumpyData(self,dat,method):\n",
        "\n",
        "      ret = np.zeros([self.params['VolSize'][0], self.params['VolSize'][1], self.params['VolSize'][2]], dtype=np.float32)\n",
        "\n",
        "      img=dat\n",
        "\n",
        "      #we rotate the image according to its transformation using the direction and according to the final spacing we want\n",
        "      factor = np.asarray(img.GetSpacing()) / [self.params['dstRes'][0], self.params['dstRes'][1],\n",
        "                                                self.params['dstRes'][2]]\n",
        "\n",
        "      factorSize = np.asarray(img.GetSize() * factor, dtype=float)\n",
        "\n",
        "      newSize = np.max([factorSize, self.params['VolSize']], axis=0)\n",
        "\n",
        "      newSize = newSize.astype(dtype=int).tolist()\n",
        "      \n",
        "      T=sitk.AffineTransform(3)\n",
        "      T.SetMatrix(img.GetDirection())\n",
        "\n",
        "      resampler = sitk.ResampleImageFilter()\n",
        "      resampler.SetReferenceImage(img)\n",
        "      resampler.SetOutputSpacing([self.params['dstRes'][0], self.params['dstRes'][1], self.params['dstRes'][2]])\n",
        "      resampler.SetSize(newSize)\n",
        "      resampler.SetInterpolator(method)\n",
        "\n",
        "      if self.params['normDir']:\n",
        "        resampler.SetTransform(T.GetInverse())\n",
        "\n",
        "      imgResampled = resampler.Execute(img)\n",
        "\n",
        "\n",
        "      imgCentroid = np.asarray(newSize, dtype=float) / 2.0\n",
        "\n",
        "      imgStartPx = (imgCentroid - self.params['VolSize'] / 2.0).astype(dtype=int).tolist()\n",
        "\n",
        "      regionExtractor = sitk.RegionOfInterestImageFilter()\n",
        "      regionExtractor.SetSize(list(self.params['VolSize'].astype(dtype=int).tolist()))\n",
        "      regionExtractor.SetIndex(imgStartPx)\n",
        "\n",
        "      imgResampledCropped = regionExtractor.Execute(imgResampled)\n",
        "\n",
        "      ret = np.transpose(sitk.GetArrayFromImage(imgResampledCropped).astype(dtype=float), [2, 1, 0])\n",
        "\n",
        "      return ret\n",
        "\n",
        "\n",
        "    # loads data\n",
        "    def load_data(self):\n",
        "      images =  [f for f in os.listdir(self.dir) if 'segmentation' not in f and 'raw' not in f] \n",
        "      masks = [f for f in os.listdir(self.dir) if 'segmentation' in f and 'raw' not in f]\n",
        "      images = sorted(images)\n",
        "      masks = sorted(masks)\n",
        "      return images , masks\n",
        "    \n",
        "    def process_img(self, filepaths):\n",
        "      images = []\n",
        "      cwd = os.getcwd()\n",
        "      os.chdir(self.dir)\n",
        "      for filepath in filepaths:\n",
        "        rescalFilt=sitk.RescaleIntensityImageFilter()\n",
        "        rescalFilt.SetOutputMaximum(1)\n",
        "        rescalFilt.SetOutputMinimum(0)\n",
        "        img =rescalFilt.Execute(sitk.Cast(sitk.ReadImage(filepath),sitk.sitkFloat32))\n",
        "        img = self.getNumpyData(img, sitk.sitkLinear)\n",
        "        img = img.reshape(*img.shape, 1)\n",
        "        images.append(img)\n",
        "      os.chdir(cwd)\n",
        "      images = np.array(images, dtype= np.float32)\n",
        "      images =  tf.convert_to_tensor(images)\n",
        "      return images\n",
        "    \n",
        "\n",
        "    def process_mask(self, maskpaths):\n",
        "      cwd = os.getcwd()\n",
        "      os.chdir(self.dir)\n",
        "      masks = []\n",
        "      for maskpath in maskpaths:\n",
        "        mask = sitk.Cast(sitk.ReadImage(maskpath)>0.5,sitk.sitkFloat32)\n",
        "        mask = self.getNumpyData(mask, sitk.sitkLinear)\n",
        "        mask = (mask > 0.5).astype(dtype=np.float32)\n",
        "        mask = mask.reshape(*mask.shape, 1)\n",
        "        masks.append(mask)\n",
        "      os.chdir(cwd)\n",
        "      masks = np.array(masks, dtype= np.float32)\n",
        "      masks =  tf.convert_to_tensor(masks)\n",
        "      return masks  \n",
        "\n",
        "\n",
        "    # Call this to get the data\n",
        "    def get_dataset(self):\n",
        "      \n",
        "      x,y = self.load_data()\n",
        "      print(f\"Total images:- {len(x)}, masks:- {len(y)}\")\n",
        "      x,y = self.process_img(x), self.process_mask(y)\n",
        "      dataset = tf.data.Dataset.from_tensor_slices((x,y))\n",
        "      dataset = dataset.shuffle(buffer_size=10)\n",
        "      # dataset = dataset.map(\n",
        "      #   lambda x, y: tf.numpy_function(\n",
        "      #       func = self.process_img,\n",
        "      #       inp = [x],\n",
        "      #       Tout= tf.Tensor,\n",
        "      #   ), tf.numpy_function(\n",
        "      #       func = self.process_mask,\n",
        "      #       inp = [y],\n",
        "      #       Tout= tf.Tensor,\n",
        "      #   )\n",
        "      # )\n",
        "      dataset = dataset.batch(batch_size=self.batch_size)\n",
        "      return  dataset\n"
      ],
      "metadata": {
        "id": "ZiZT2Yx3ijLv"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = CustomDataset('./dataset/train', batch_size=BATCH_SIZE).get_dataset()\n",
        "# test = CustomDataset('./dataset/test', batch_size=1).get_dataset()\n",
        "\n",
        "for x,y in train.take(2):\n",
        "  print(x.shape,y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1SM4HSBmoNa",
        "outputId": "ce4e1cb5-5064-4aa7-ebe3-153c381231ac"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images:- 50, masks:- 50\n",
            "(2, 128, 128, 64, 1) (2, 128, 128, 64, 1)\n",
            "(2, 128, 128, 64, 1) (2, 128, 128, 64, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Pipeline: "
      ],
      "metadata": {
        "id": "8ZSYaTS8jcjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mod = VNet(input_shape=(128,128,64,1,), batch_size = BATCH_SIZE)\n",
        "mod.compile(loss='mse', optimizer= Adam(learning_rate=1e-5))\n",
        "mod.fit(train, epochs= 3, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41gtZvO4sETE",
        "outputId": "b42318e4-773c-4d92-bac7-763896087597"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "25/25 [==============================] - 51s 2s/step - loss: 0.9655\n",
            "Epoch 2/3\n",
            "25/25 [==============================] - 49s 2s/step - loss: 0.9655\n",
            "Epoch 3/3\n",
            "25/25 [==============================] - 49s 2s/step - loss: 0.9655\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fea4a32fa50>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "uuzuIktaifks"
      ]
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.12 ('isic')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "2ed40115b9311c990e0db03d45bc5fce15d49910c366a778b1744ea7c53758dc"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}